<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Blogs | Org Mode</title><meta name=keywords content><meta name=description content="Blogs - Org Mode"><meta name=author content="Me"><link rel=canonical href=https://kylestones.github.io/blog/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><link rel=icon href=https://kylestones.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://kylestones.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://kylestones.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://kylestones.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://kylestones.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://kylestones.github.io/blog/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Blogs"><meta property="og:description" content="ExampleSite description"><meta property="og:type" content="website"><meta property="og:url" content="https://kylestones.github.io/blog/"><meta property="og:image" content="https://kylestones.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://kylestones.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Blogs"><meta name=twitter:description content="ExampleSite description"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Blogs","item":"https://kylestones.github.io/blog/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://kylestones.github.io accesskey=h title="Home (Alt + H)"><img src=https://kylestones.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://kylestones.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://kylestones.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://example.org title=example.org><span>example.org</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://kylestones.github.io>Home</a></div><h1>Blogs
<a href=index.xml title=RSS aria-label=RSS><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><header class=entry-header><h2>损失函数</h2></header><div class=entry-content><p>为了度量算法关于某个数据集的性能，我们需要损失函数。当算法希望生成比真实值一个较小的数字，那么损失函数中应该体现出现，较 大的输出比较小的输出有更大的惩罚。
Loss: Used to evaluate and diagnose model optimization only. Metric: Used to evaluate and choose models in the context of the project. Mean Squared Error MSE 是经常被使用的损失函数，易于理解，且表现很好。
take the difference between your predictions and the ground truth square it average it out across the whole dataset def MSE(y_predicted, y): squared_error = (y_predicted, y) ** 2 sum_squared_error = np.sum(squared_error) mse = sum_squared_error / y.size return mse Cross Entropy Loss (Log Loss) 交叉熵损失经常用于分类问题。函数定义如下...</p></div><footer class=entry-footer><span title='2018-08-17 00:00:00 +0000 UTC'>August 17, 2018</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;398 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to 损失函数" href=https://kylestones.github.io/blog/machinelearning/loss-function/></a></article><article class=post-entry><header class=entry-header><h2>TensorFlow</h2></header><div class=entry-content><p>架构 阅读大神的 《TensorFlow 内核剖析》 对 TensorFlow 的整个代码框架有了一些了解，以下是读书笔记。
Graph (计算图)是 TensorFlow 领域模型的核心。计算图就是节点与边的集合，是一个 DAG (有向无环图)图。
Node(节点)持有零条或多条输入/输出的边，分别使用 in_edges， out_edges 表示。
Edge(边) 持有前驱节点与后驱节点，从而实现了计算图的连接，也是计算图前向遍历，后向遍历的衔接点。边上的数据以 Tensor 的形 式传递。计算图中存在两类边：
普通边：用于承载 Tensor，常用实线表示； 控制依赖：控制节点的执行顺序，常用虚线表示。 TensorFlow 计算的单位是 OP，它表示了某种抽象计算。通过定义 OP 来构建 DAG 图。OP 拥有 0 个或多个「输入/输出」，及其 0 个 或多个「属性」。其中，输入/输出以Tensor 的形式存在。在系统实现中，OP 的元数据使用 Protobuf 格式的 OpDef 描述，实现前端与 后端的数据交换，及其领域模型的统一。OpDef 定义包括 OP 的名字，输入输出列表，属性列表，优化选项等。其中，属性常常用于描述 输入/输出的类型，大小，默认值，约束，及OP 的其他特性。
计算图的执行过程将按照 DAG 的拓扑排序，依次启动 OP 的运算。其中，如果存在多个入度为 0 的节点，TensorFlow 运行时可以实现 并发，同时执行多个 OP 的运算，提高执行效率。
架构设计 TensorFlow 遵循良好的分层架构：
front end ： 用户接口，负责构造计算图 runtime ： 实现计算图的拆分。提供本地运行模式和分布式运行模式，两者共享大部分设计和实现 计算层 ： 基于 Eigen 实现计算的逻辑实现；同时支持各种硬件的并行加速 通信层 ： 基于 gRPC 实现组件间的数据交换。同时支持 RDMA 设备层 ： 支持多种异构计算设备。实际执行计算的载体 前端系统 Client 是前端系统的主要组成部分，它是一个支持多语言的编程环境，且对 Python 和 C++ 的支持比较完善。实现时通过 Swig 完成对 后端 C++ 的调用。基于这些编程接口来构造计算图。...</p></div><footer class=entry-footer><span title='2018-08-12 00:00:00 +0000 UTC'>August 12, 2018</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;502 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to TensorFlow" href=https://kylestones.github.io/blog/machinelearning/tensorflow/></a></article><article class=post-entry><header class=entry-header><h2>Deep Learning</h2></header><div class=entry-content><p>神经网络和深度学习 神经网络概论 结构化数据(structured data)：每个特征都有清晰、明确有意义的定义；比如房屋的面积，人的身高等 非结构化数据(unstructured data)：特征无法精确定义；比如图像的像素点，音频，文字 人类很擅长处理结构化的数据，但机器很不擅长。而归功于深度学习，使得机器在非结构化数据的处理有了明显的提高；但是现在比较挣 钱的仍然是让机器处理结构化数据，如广告投放、理解处理公司的海量数据并进行预测等。吴恩达希望设计的网络可以处理结构化数据也 可以处理非结构化的数据。
每个神经元类似一个乐高积木(Lego brick) ，将许多神经元堆叠在一起就形成了一个较大的神经网络。而且并不会人为决定每个神经元 的作用，而是由神经网络自己决定每个神经元的作用。如果给神经网络足够多的训练数据，其非常擅长计算从输入到输出的精确映射。神 经网络在监督学习中效果很好很强大。
神经网络有不同的种类，有用于处理图像的 CNN(Convolution Neural Network)、处理一维序列的 RNN(Recurrent Neural Network)、以 及自动驾驶中用于处理雷达数据的混合神经网络(Hybrid Neural Network)[对于复杂的问题，需要自行构建网络的架构；和机器学习中的 算法一样，针对具体的问题，需要去做具体的优化，而不是一成不变的使用基本的算法]
scale 使得神经网络在最近流行起来，这里的 scale 并不单单指神经网络的规模，还包括数据的规模。当训练样本不是很大的时候，神 经网络与传统的机器学习算法之间的优劣并不明显，此时主要取决有人为设计算法的技巧和能力以及算法处理的细节，可能一个设计良好 的 SVM 算法结果要优于一个神经网络的效果；但是随着样本量不断变大，传统的机器学习算法的性能会在达到一定的性能之后效果变无 法继续提升，而神经网络此时的效果将明显领先于传统的算法[需要很大的样本，且网络的规模越大，性能越好]。数据、计算能力、算法 都促使了深度学习的发展；算法的主要改进都在加快算法的速度，比如使用 ReLU 函数替代 sigmoid 函数就大大加快了算法的训练速度， 因为 sigmoid 函数在自变量趋向于正负无穷大的时候，导数趋向于 0，而使用梯度下降法，梯度的减小将使得参数的变化变得缓慢，从 而学习将变得缓慢；而 ReLU 函数右侧的斜率始终为 1，由于斜率不会逐渐趋向于 0，使得算法训练速度大大提高（ReLu: rectified linear unit ，修正线性单元；修正指的是取不小于 0 的值）。速度的提升使得我们可以训练大型的网络或者在一定的时间内完成网络 的训练。而且训练神经网络的过程一般是 idea - code - experiment - idea 不断循环，迭代的更快使得验证自己的想法更加快速得到 验证，将有机会取验证更多的想法，从而更有可能找到合适的结果。
1989 年 Robert Hecht-Nielsen 证明了万能逼近定理：对于任何闭区间的一个连续函数都可以用一个隐含层的 BP 网络来逼近（完成任 意m 维到 n 维的映射）。虽然如此，但是若要模拟复杂的函数可能需要特别特别多的隐层神经元，因此现代网络总是加大网络的深度， 以让每一层的函数尽量简单，而整个网络完成复杂的映射。...</p></div><footer class=entry-footer><span title='2018-07-12 00:00:00 +0000 UTC'>July 12, 2018</span>&nbsp;·&nbsp;22 min&nbsp;·&nbsp;4670 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to Deep Learning" href=https://kylestones.github.io/blog/machinelearning/deeplearning/></a></article><article class=post-entry><header class=entry-header><h2>Machine Learning</h2></header><div class=entry-content><p>ML *机器学习* machine learning: Field of study that gives computers the ability to learn without being explicitly program.
机器学习并不是仅仅是若干算法的堆积，学会“十大算法”，熟练掌握具体算法算法的推导与编程实现，并不能让所有问题迎刃而解，因为 现实世界的问题千变万化。而应该像张无忌那样，忘记张三丰传授的太极剑法的具体招式，而只记住一些规则和套路，从而根据敌人的招 式去不断变化自己的招式，达到以不变应万变的效果。或者说用 Andrew Ng 的话，要成为一个 master carpenter （顶级木匠），可以 灵活使用工具来制造桌椅，只有手艺差的木匠才会抱怨工具不合适。因此必须把握算法背后的思想脉络，针对具体的任务特点，对现有套 路进行改造融通；要记住算法是 死 的，思想才是 活 的。
数据库提供数据管理技术，机器学习提供数据分析技术。
Supervised Learning 样本有标签的时候称为监督学习
Linear Regression 首先可以根据样本输入的维数来选择参数的个数（最终依据交叉验证的结果来选择模型和特征） \[ h_{\theta}(x) = \sum_{i=1}^{n} \theta_i x_i = \theta^{T}x \] 求取 \(\theta\) 的策略：在训练集上使得 \(h(x)\) 尽可能接近 y 。那么就涉及到距离的定义，距离通常定义为两者差的平方。因此 损失函数(cost function)定义为 \[ J(\theta) = \frac{1}{2} \sum_{i=1}^m (h_{\theta}(x^{(i)}) - y^{(i)})^2 \]
认为数据服从高斯分布 \(y|x;\theta \thicksim (\mu, \sigma^2)\) ，即其前置概率估计是高斯分布。...</p></div><footer class=entry-footer><span title='2018-06-22 00:00:00 +0000 UTC'>June 22, 2018</span>&nbsp;·&nbsp;25 min&nbsp;·&nbsp;5289 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to Machine Learning" href=https://kylestones.github.io/blog/machinelearning/machine-learning/></a></article><article class=post-entry><header class=entry-header><h2>C++</h2></header><div class=entry-content><p>头文件 #include &lt;cctype> // C++ 头文件，开头的 C 表明来自 C 语言，但更符合 C++ 规范 #include &lt;ctype.h> // C 语言头文件；不应该在 C++ 中使用 // 为啥 C++ 的头文件名都没有 .h 后缀呀？ // IO 库 #include &lt;iostream> // 容器 #include &lt;vector> #include &lt;list> #include &lt;deque> #include &lt;bitset> #include &lt;stack> #include &lt;queue> #include &lt;priority_queue> 命名空间 namespace kyle { // 嵌套命名空间 namespace sanshi { ... } } // 命名空间重命名 作用域 scope 全局作用域：定义在所有函数外部 局部作用域：定义在函数内部 语句作用域：for 循环中，C 语言中不可以在 for 循环语句中定义变量 局部变量 hide 全局变量。...</p></div><footer class=entry-footer><span title='2018-05-30 00:00:00 +0000 UTC'>May 30, 2018</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;817 words&nbsp;·&nbsp;Kyle Three Stones</footer><a class=entry-link aria-label="post link to C++" href=https://kylestones.github.io/blog/apue/cpp/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://kylestones.github.io/blog/page/6/>« Prev</a>
<a class=next href=https://kylestones.github.io/blog/page/8/>Next »</a></nav></footer></main><footer class=footer><span>&copy; 2022 <a href=https://kylestones.github.io>Org Mode</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>