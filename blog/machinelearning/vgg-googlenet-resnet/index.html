<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>VGG GoogLeNet ResNet | Org Mode</title><meta name=keywords content="深度学习"><meta name=description content="VGG VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION 论文表明增加网络的深度可能提高网络的性能，论文成功将网络的深度推到 16-19 层 使用 small size (3x3) filter ：两层 3x3 的卷积与 5x5 的卷积等效，三层 3x3 的卷积与 7x7 的卷积等效；选用小尺寸的 filter 可以减小参数 第一层卷积的滤波器的个数是 64 ，之后每经过一个 max-pooling 层都将滤波器的个数乘 2，直到最大为 512 之后不再继续翻倍 Not all the conv layer are followed by max-pooling. 论文为了训练 19 层深层网络，先构建了一些浅层的网络，用于预训练，然后逐渐使用预训练好的浅层网络参数对深层的网络进行初始化。 不过文章中作者也指出，写完 paper 后发现，使用随机初始化是不需要预训练的。看来大神们发 paper 也是历经坎坷呀。
GoogLeNet 强调算法的重要性，比硬件、大的数据量更加重要。Most of the progress is not just the result of more powerful hardware, larger dataset and bigger models, but mainly a consequence of new ideas, algorithms and improved network architechtures."><meta name=author content="Kyle Three Stones"><link rel=canonical href=https://kylestones.github.io/blog/machinelearning/vgg-googlenet-resnet/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://kylestones.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://kylestones.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://kylestones.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://kylestones.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://kylestones.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="VGG GoogLeNet ResNet"><meta property="og:description" content="VGG VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION 论文表明增加网络的深度可能提高网络的性能，论文成功将网络的深度推到 16-19 层 使用 small size (3x3) filter ：两层 3x3 的卷积与 5x5 的卷积等效，三层 3x3 的卷积与 7x7 的卷积等效；选用小尺寸的 filter 可以减小参数 第一层卷积的滤波器的个数是 64 ，之后每经过一个 max-pooling 层都将滤波器的个数乘 2，直到最大为 512 之后不再继续翻倍 Not all the conv layer are followed by max-pooling. 论文为了训练 19 层深层网络，先构建了一些浅层的网络，用于预训练，然后逐渐使用预训练好的浅层网络参数对深层的网络进行初始化。 不过文章中作者也指出，写完 paper 后发现，使用随机初始化是不需要预训练的。看来大神们发 paper 也是历经坎坷呀。
GoogLeNet 强调算法的重要性，比硬件、大的数据量更加重要。Most of the progress is not just the result of more powerful hardware, larger dataset and bigger models, but mainly a consequence of new ideas, algorithms and improved network architechtures."><meta property="og:type" content="article"><meta property="og:url" content="https://kylestones.github.io/blog/machinelearning/vgg-googlenet-resnet/"><meta property="og:image" content="https://kylestones.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2018-08-22T00:00:00+00:00"><meta property="article:modified_time" content="2018-08-22T00:00:00+00:00"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://kylestones.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="VGG GoogLeNet ResNet"><meta name=twitter:description content="VGG VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION 论文表明增加网络的深度可能提高网络的性能，论文成功将网络的深度推到 16-19 层 使用 small size (3x3) filter ：两层 3x3 的卷积与 5x5 的卷积等效，三层 3x3 的卷积与 7x7 的卷积等效；选用小尺寸的 filter 可以减小参数 第一层卷积的滤波器的个数是 64 ，之后每经过一个 max-pooling 层都将滤波器的个数乘 2，直到最大为 512 之后不再继续翻倍 Not all the conv layer are followed by max-pooling. 论文为了训练 19 层深层网络，先构建了一些浅层的网络，用于预训练，然后逐渐使用预训练好的浅层网络参数对深层的网络进行初始化。 不过文章中作者也指出，写完 paper 后发现，使用随机初始化是不需要预训练的。看来大神们发 paper 也是历经坎坷呀。
GoogLeNet 强调算法的重要性，比硬件、大的数据量更加重要。Most of the progress is not just the result of more powerful hardware, larger dataset and bigger models, but mainly a consequence of new ideas, algorithms and improved network architechtures."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Blogs","item":"https://kylestones.github.io/blog/"},{"@type":"ListItem","position":3,"name":"VGG GoogLeNet ResNet","item":"https://kylestones.github.io/blog/machinelearning/vgg-googlenet-resnet/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"VGG GoogLeNet ResNet","name":"VGG GoogLeNet ResNet","description":"VGG VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION 论文表明增加网络的深度可能提高网络的性能，论文成功将网络的深度推到 16-19 层 使用 small size (3x3) filter ：两层 3x3 的卷积与 5x5 的卷积等效，三层 3x3 的卷积与 7x7 的卷积等效；选用小尺寸的 filter 可以减小参数 第一层卷积的滤波器的个数是 64 ，之后每经过一个 max-pooling 层都将滤波器的个数乘 2，直到最大为 512 之后不再继续翻倍 Not all the conv layer are followed by max-pooling. 论文为了训练 19 层深层网络，先构建了一些浅层的网络，用于预训练，然后逐渐使用预训练好的浅层网络参数对深层的网络进行初始化。 不过文章中作者也指出，写完 paper 后发现，使用随机初始化是不需要预训练的。看来大神们发 paper 也是历经坎坷呀。\nGoogLeNet 强调算法的重要性，比硬件、大的数据量更加重要。Most of the progress is not just the result of more powerful hardware, larger dataset and bigger models, but mainly a consequence of new ideas, algorithms and improved network architechtures.","keywords":["深度学习"],"articleBody":" VGG VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION 论文表明增加网络的深度可能提高网络的性能，论文成功将网络的深度推到 16-19 层 使用 small size (3x3) filter ：两层 3x3 的卷积与 5x5 的卷积等效，三层 3x3 的卷积与 7x7 的卷积等效；选用小尺寸的 filter 可以减小参数 第一层卷积的滤波器的个数是 64 ，之后每经过一个 max-pooling 层都将滤波器的个数乘 2，直到最大为 512 之后不再继续翻倍 Not all the conv layer are followed by max-pooling. 论文为了训练 19 层深层网络，先构建了一些浅层的网络，用于预训练，然后逐渐使用预训练好的浅层网络参数对深层的网络进行初始化。 不过文章中作者也指出，写完 paper 后发现，使用随机初始化是不需要预训练的。看来大神们发 paper 也是历经坎坷呀。\nGoogLeNet 强调算法的重要性，比硬件、大的数据量更加重要。Most of the progress is not just the result of more powerful hardware, larger dataset and bigger models, but mainly a consequence of new ideas, algorithms and improved network architechtures.\n论文和 VGG 同样，希望建立一个 deeper network 。同样也引用了盗梦空间中的 meme : we need to go deeper. 表明作者搭建深度网 络的决心。论文成功训练了一个 22 层的卷积神经网络。\n最主要的思想就是 inception module 。一个 inception module 集合了 1x1 、3x3、 5x5 、pooling 不同尺寸的 filter ，让网络 自己学习，决定去使用多大尺寸 filter 可以更好的提取 feature 。当然这会大大增加网络参数的个数，为了减少参数，filter size越 大，使用越少的 channel ，而且在 3x3 和 5x5 的 filter 之前先使用 1x1 CONV 来减少 channel 的个数。所有不同尺寸的卷积得到的 feature map 按照不同的 channel 堆叠起来组成本层网络的输出。这就要求不同尺寸卷积操作都使用 same padding 确保执行卷积之后 feature map 都相同，且 inception module 中的 max-pooling 也要求步长为 1 。\n构建好一个 inception module 后，只需要将他们堆叠起来就可以构成一个完整的卷积神经网络。在 GoogLeNet 中作者总共使用了 9 个 inception module ，每个 inception module 包含两层（由于使用了 1x1 CONV），总共是 18 层。再加上最开始的 7x7、 1x1、 3x3 三个卷积层以及最后的一个 FC 层，总共有 22 层。除了 inception module 中，网络共使用了 4 次 max-pooling ，在第一个 inception module 之前使用了两次，第二个 inception module 之后和倒数第二个 inception module 之前分别使用了一次。\n而且由于 inception module 会大大增加参数的个数，所以作者只在 higher layer 使用 inception module ，在 lower layer 仍然使 用 traditional convolution 。而且在有些 inception module 之后使用了 max-pooling 。\n论文在测试没有使用 10-crop （原图和水平翻转之后的图像都分别在左上角、右上角、左下角、右下角、中间分别进行 crop），而是进 行了 144 次 crop ，好像有点太多了。。。\n其他的部分没有太看懂，比如作者说的稀疏 local sparse structure、Hebbian Principle、等都有点不知所云。\nHebbian principle : neurons that fire together, wire together.\nResNet ResNet 更是专门为了训练 deeper network 而提出的，成功训练了一个 1202 层的网络（虽然效果并不如 110 层网络效果好）。\n由于什么未知的原因，直接堆叠卷积层，网络的深度到达一定的层数之后，训练误差会变大，而不是继续减小。并且这种现象无法通过增 加迭代次数来改变。\n其实感觉作者的想法也很简单粗暴，网络比较层数比较深的时候，通过一个跨越中间卷积层的连接让网络变得不再那么深。当然这是我的 理解。论文中介绍说源自于先构建一个 shallow 的网络，然后再添加一个额外的层组成更深的网络。由此作者将这些额外添加的层两端 直接增加一个连接，类似电路上直接引用一条线，与其并行的线路直接短路。当然并不想让这些额外的层完全短路，否则这些额外层将毫 无意义。但这条线将起主导作用，额外的网络层影响较小。\n作者称这条连接为 shortcut connection ，该 shortcut connection 传递 identity mapping ，起主导作用；而中间添加的额外的层传 递的是residual mapping，只会传递一些剩余的残差，作者的实验也表明残差几乎总是接近 0 。\n文中 shortcut connect 中间只有两层或者三层卷积，作者指出更多层也可以，但是为什么没有使用呢？可能跨越太多层会使得网络变得 太简单，而无法得到很好的训练效果，可能在 1202 层中使用了跨越很多层的连接，待考察。\n\\begin{align*} \\mathcal{H}(x) = \\mathcal{F}(x) + x \\end{align*}\n一个残差块称为 building block ，其中 x 是残差块的输入， \\(\\mathcal{H(x)}\\) 是残差块的输出， \\(\\mathcal{F(x)}\\) 是残差。 shortcut connection 直接将 x 和 \\(\\mathcal{F(x)}\\) 进行 element-wise 相加，然后再执行非线性激活函数。此时要保证两者的维 数相同，若不相同需要进行线性投影。卷积层执行 element-wise add 的时候，让相对应的 channel 分别进行逐元素相加（The element-wise addition is performed on two feature maps, channel by channel.），相加后 channel 个数保持不变。filter size 也保持不变。\n文中 building block 共有两种形式，一种是直接在两个串接的 3x3 的卷积层两端添加 shortcut connection ；另一种称为 bottleneck building block，借鉴 NIN ，使用 1x1 卷积先减少 channel 的个数，执行 3x3 卷积，然后在使用 1x1 卷积增大channel 的个数。通过这样的方法构建了三层网络但是参数的个数却很少。\n文中使用 bottleneck building block 构建了 152 层的残差网络。\n处理残差块的维数不一致的时候有三种方法：(A) 直接填充 0 ；(B) 使用一个矩阵进行线性投影 (C) 将所有的 shortcut connection 都进行投影，维数一致的时候同样进行投影。文中的实验表明 (C) 比 (B) 效果稍微好一点， (B) 比 (A) 效果稍微好一点，但都很有限。 所以此处的投影对于网络深度加深时正确率下降的影响很小，而 identity shortcut 是非常重要的。也就是采用那种方法都可以。论文 中采用了 (B)。\n整个 152 层的网络也学习 VGG ，除了第一层卷积使用 7x7 filter 外，只使用 1x1 和 3x3 的 filter 。最后使用得到 2048 个 feature map ，然后使用 global average pooling 得到 2048 个节点，然后经过一个 1000 个节点 FC 层经过 Softmax 输出 ImageNet 不同类别的概率。\nDenseNet 文中最后指出表面上 DenseNet 和 ResNet 很相似，但实质上并不一样（ResNet 是 element-wise 相加，而 DenseNet 是将 feature maps 进行堆叠）。但是毕竟是受到 ResNet 的启发，并在其之上进行的改进。\nDenseNet 同样是先构建 dense block ，然后让 dense block 不断堆叠得到整个网络。每个 dense block 也比较简单，就是让该 dense block 内的每一个卷积层的输出与后面所有层都进行连接；或者说是每一层都与前面所有层的输出进行连接（Each layer takes all preceding feature-maps as input.），用公式可以表示为 \\(X_l = H_l ( [ X_0,X_1,\\ldots,X_{l-1} ] )\\) 。另外与 ResNet 不同的 是，ResNet 是将 skip connect 进行 element-wise 相加，而这里则是将前面层的 feature maps 与后面层的 feature maps 作为不同 的 channel 进行堆叠，并不进行逐元素相加，作者认为逐元素相加无法很好的发挥跨连接的性能。因此作者设计的 dense block 内的所 有卷积层的 feature maps 有相同的空间尺寸，即一个 dense block 没有下采样操作。\nGrowth rate : 作者将每个 dense block 内，一个卷积层输出的 channel 的个数称为 growth rate。不像其他的网络架构使用很多滤波 器如 512、1024 个 channel 来提取特征，dense block 中使用很少的 channel 来提取特征，作者取用了 k = 32 。\nl 表示一个 dense block 中卷积层的个数，作者取用了 l = 6, 12, 48, 32, 64 等值。最终组成了 121, 169, 201, 264 层 DenseNet 网络。\nComposite function : H_l = BN + ReLU + 3x3 CONV。由于 dense block 进行了密集连接，所以 dense block 内后面的卷积层输入的 channel 个数将会很大，所以作者在 3x3 卷积之前进行了 1x1 CONV 来压缩通道的个数。因此 H_l = BN + ReLU + 1x1 CONV + BN + ReLU + 3x3 CONV .称为 Bottleneck layers\nPooling layers : BN + 1x1 CONV + 2x2 average pooling 。作者称 dense block 中间的连接为 transition layer。为了进一步压缩 模型，这里的 1x1 卷积将用于减少 channel 的个数，将 channel 的个数由 m 减少到 \\(\\theta m, \\ \\theta \u003c 1\\) ，作者采用了 \\(\\theta = 0.5\\) 。同时采用 Bottleneck 和 Compression 的网络架构称为 DenseNet-BC.\n文中使用了 4 个 dense block ，前面两个 dense block 使用了相同的 L ，后面两个 dense block 的个数不同而形成了不同层数的网 络。\nDenseNet 有更少的参数，更少的运算时间，却可以达到更好的效果。\n猜想 ： 假如把 dense block 当做一种新形式的卷积层，然后按照相似的形式对多个 dense block 进行密集连接，组成更大形式的网 络会怎样？\nNIN 1x1 CONV 对不同的 channel 相同位置的节点进行卷积，来减少 channel 的个数。不仅可以融合不同 channel 的特征，也可以有效减少参数。\nGlobal Average Pooling 全连接层参数过多，容易过拟合，需要 Dropout 等方法来预防。而且这种将前面提取到的特征直接堆叠起来的方法有点不自然。所有作 者提出让每一个 feature map 的全局平均值作为一个节点，有多少个类别就生成多少个 feature map ，然后将所有 feature map 的平 均值输入到 Softmax 进行分类，这样每一个 feature map 代表一类，相比于全连接层，其意义更加明确。而且无需额外的参数，同时可 以融合空间信息。\nTake the average of each feature map, and the resulting map is fed directly into the softmax layer. Generate one feature map for each corresponding category of the classification task. Feature map can be easily interpreted as categories confidence map.\nFCN Fully Convolutional Networks for Semantic Segmentation\n将卷积神经网络中的全连接层变成卷积层，让整个网络全部由卷积操作组成，故称为全卷积网络。\n","wordCount":"723","inLanguage":"en","datePublished":"2018-08-22T00:00:00Z","dateModified":"2018-08-22T00:00:00Z","author":{"@type":"Person","name":"Kyle Three Stones"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://kylestones.github.io/blog/machinelearning/vgg-googlenet-resnet/"},"publisher":{"@type":"Organization","name":"Org Mode","logo":{"@type":"ImageObject","url":"https://kylestones.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://kylestones.github.io accesskey=h title="Home (Alt + H)"><img src=https://kylestones.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://kylestones.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://kylestones.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://example.org title=example.org><span>example.org</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://kylestones.github.io>Home</a>&nbsp;»&nbsp;<a href=https://kylestones.github.io/blog/>Blogs</a></div><h1 class=post-title>VGG GoogLeNet ResNet</h1><div class=post-meta><span title='2018-08-22 00:00:00 +0000 UTC'>August 22, 2018</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;723 words&nbsp;·&nbsp;Kyle Three Stones&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/blog/machinelearning/vgg-GoogLeNet-resnet.org rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><div id=outline-container-headline-1 class=outline-3><h3 id=headline-1>VGG</h3><div id=outline-text-headline-1 class=outline-text-3><p>VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION</p><ol><li>论文表明增加网络的深度可能提高网络的性能，论文成功将网络的深度推到 16-19 层</li><li>使用 small size (3x3) filter ：两层 3x3 的卷积与 5x5 的卷积等效，三层 3x3 的卷积与 7x7 的卷积等效；选用小尺寸的
filter 可以减小参数</li><li>第一层卷积的滤波器的个数是 64 ，之后每经过一个 max-pooling 层都将滤波器的个数乘 2，直到最大为 512 之后不再继续翻倍</li><li>Not all the conv layer are followed by max-pooling.</li></ol><p>论文为了训练 19 层深层网络，先构建了一些浅层的网络，用于预训练，然后逐渐使用预训练好的浅层网络参数对深层的网络进行初始化。
不过文章中作者也指出，写完 paper 后发现，使用随机初始化是不需要预训练的。看来大神们发 paper 也是历经坎坷呀。</p></div></div><div id=outline-container-headline-2 class=outline-3><h3 id=headline-2>GoogLeNet</h3><div id=outline-text-headline-2 class=outline-text-3><p>强调算法的重要性，比硬件、大的数据量更加重要。Most of the progress is not just the result of more powerful hardware,
larger dataset and bigger models, but mainly a consequence of new ideas, algorithms and improved network architechtures.</p><p>论文和 VGG 同样，希望建立一个 deeper network 。同样也引用了盗梦空间中的 meme : we need to go deeper. 表明作者搭建深度网
络的决心。论文成功训练了一个 22 层的卷积神经网络。</p><p><strong>最主要的思想就是 inception module</strong> 。一个 inception module 集合了 1x1 、3x3、 5x5 、pooling 不同尺寸的 filter ，让网络
自己学习，决定去使用多大尺寸 filter 可以更好的提取 feature 。当然这会大大增加网络参数的个数，为了减少参数，filter size越
大，使用越少的 channel ，而且在 3x3 和 5x5 的 filter 之前先使用 1x1 CONV 来减少 channel 的个数。所有不同尺寸的卷积得到的
feature map 按照不同的 channel 堆叠起来组成本层网络的输出。这就要求不同尺寸卷积操作都使用 same padding 确保执行卷积之后
feature map 都相同，且 inception module 中的 max-pooling 也要求步长为 1 。</p><p>构建好一个 inception module 后，只需要将他们堆叠起来就可以构成一个完整的卷积神经网络。在 GoogLeNet 中作者总共使用了 9 个
inception module ，每个 inception module 包含两层（由于使用了 1x1 CONV），总共是 18 层。再加上最开始的 7x7、 1x1、 3x3
三个卷积层以及最后的一个 FC 层，总共有 22 层。除了 inception module 中，网络共使用了 4 次 max-pooling ，在第一个
inception module 之前使用了两次，第二个 inception module 之后和倒数第二个 inception module 之前分别使用了一次。</p><p>而且由于 inception module 会大大增加参数的个数，所以作者只在 higher layer 使用 inception module ，在 lower layer 仍然使
用 traditional convolution 。而且在有些 inception module 之后使用了 max-pooling 。</p><p>论文在测试没有使用 10-crop （原图和水平翻转之后的图像都分别在左上角、右上角、左下角、右下角、中间分别进行 crop），而是进
行了 144 次 crop ，好像有点太多了。。。</p><p>其他的部分没有太看懂，比如作者说的稀疏 local sparse structure、Hebbian Principle、等都有点不知所云。</p><p>Hebbian principle : neurons that fire together, wire together.</p></div></div><div id=outline-container-headline-3 class=outline-3><h3 id=headline-3>ResNet</h3><div id=outline-text-headline-3 class=outline-text-3><p>ResNet 更是专门为了训练 deeper network 而提出的，成功训练了一个 1202 层的网络（虽然效果并不如 110 层网络效果好）。</p><p>由于什么未知的原因，直接堆叠卷积层，网络的深度到达一定的层数之后，训练误差会变大，而不是继续减小。并且这种现象无法通过增
加迭代次数来改变。</p><p>其实感觉作者的想法也很简单粗暴，网络比较层数比较深的时候，通过一个跨越中间卷积层的连接让网络变得不再那么深。当然这是我的
理解。论文中介绍说源自于先构建一个 shallow 的网络，然后再添加一个额外的层组成更深的网络。由此作者将这些额外添加的层两端
直接增加一个连接，类似电路上直接引用一条线，与其并行的线路直接短路。当然并不想让这些额外的层完全短路，否则这些额外层将毫
无意义。但这条线将起主导作用，额外的网络层影响较小。</p><p>作者称这条连接为 shortcut connection ，该 shortcut connection 传递 identity mapping ，起主导作用；而中间添加的额外的层传
递的是residual mapping，只会传递一些剩余的残差，作者的实验也表明残差几乎总是接近 0 。</p><p>文中 shortcut connect 中间只有两层或者三层卷积，作者指出更多层也可以，但是为什么没有使用呢？可能跨越太多层会使得网络变得
太简单，而无法得到很好的训练效果，可能在 1202 层中使用了跨越很多层的连接，待考察。</p><p>\begin{align*}
\mathcal{H}(x) = \mathcal{F}(x) + x
\end{align*}</p><p>一个残差块称为 building block ，其中 x 是残差块的输入， \(\mathcal{H(x)}\) 是残差块的输出， \(\mathcal{F(x)}\) 是残差。
shortcut connection 直接将 x 和 \(\mathcal{F(x)}\) 进行 element-wise 相加，然后再执行非线性激活函数。此时要保证两者的维
数相同，若不相同需要进行线性投影。卷积层执行 element-wise add 的时候，让相对应的 channel 分别进行逐元素相加（The
element-wise addition is performed on two feature maps, channel by channel.），相加后 channel 个数保持不变。filter size
也保持不变。</p><p>文中 building block 共有两种形式，一种是直接在两个串接的 3x3 的卷积层两端添加 shortcut connection ；另一种称为
bottleneck building block，借鉴 NIN ，使用 1x1 卷积先减少 channel 的个数，执行 3x3 卷积，然后在使用 1x1 卷积增大channel
的个数。通过这样的方法构建了三层网络但是参数的个数却很少。</p><p>文中使用 bottleneck building block 构建了 152 层的残差网络。</p><p>处理残差块的维数不一致的时候有三种方法：(A) 直接填充 0 ；(B) 使用一个矩阵进行线性投影 (C) 将所有的 shortcut connection
都进行投影，维数一致的时候同样进行投影。文中的实验表明 (C) 比 (B) 效果稍微好一点， (B) 比 (A) 效果稍微好一点，但都很有限。
所以此处的投影对于网络深度加深时正确率下降的影响很小，而 identity shortcut 是非常重要的。也就是采用那种方法都可以。论文
中采用了 (B)。</p><p>整个 152 层的网络也学习 VGG ，除了第一层卷积使用 7x7 filter 外，只使用 1x1 和 3x3 的 filter 。最后使用得到 2048 个
feature map ，然后使用 global average pooling 得到 2048 个节点，然后经过一个 1000 个节点 FC 层经过 Softmax 输出 ImageNet
不同类别的概率。</p></div></div><div id=outline-container-headline-4 class=outline-3><h3 id=headline-4>DenseNet</h3><div id=outline-text-headline-4 class=outline-text-3><p>文中最后指出表面上 DenseNet 和 ResNet 很相似，但实质上并不一样（ResNet 是 element-wise 相加，而 DenseNet 是将 feature
maps 进行堆叠）。但是毕竟是受到 ResNet 的启发，并在其之上进行的改进。</p><p>DenseNet 同样是先构建 dense block ，然后让 dense block 不断堆叠得到整个网络。每个 dense block 也比较简单，就是让该 dense
block 内的每一个卷积层的输出与后面所有层都进行连接；或者说是每一层都与前面所有层的输出进行连接（Each layer takes all
preceding feature-maps as input.），用公式可以表示为 \(X_l = H_l ( [ X_0,X_1,\ldots,X_{l-1} ] )\) 。另外与 ResNet 不同的
是，ResNet 是将 skip connect 进行 element-wise 相加，而这里则是将前面层的 feature maps 与后面层的 feature maps 作为不同
的 channel 进行堆叠，并不进行逐元素相加，作者认为逐元素相加无法很好的发挥跨连接的性能。因此作者设计的 dense block 内的所
有卷积层的 feature maps 有相同的空间尺寸，即一个 dense block 没有下采样操作。</p><p>Growth rate : 作者将每个 dense block 内，一个卷积层输出的 channel 的个数称为 growth rate。不像其他的网络架构使用很多滤波
器如 512、1024 个 channel 来提取特征，dense block 中使用很少的 channel 来提取特征，作者取用了 k = 32 。</p><p>l 表示一个 dense block 中卷积层的个数，作者取用了 l = 6, 12, 48, 32, 64 等值。最终组成了 121, 169, 201, 264 层 DenseNet
网络。</p><p>Composite function : H_l = BN + ReLU + 3x3 CONV。由于 dense block 进行了密集连接，所以 dense block 内后面的卷积层输入的
channel 个数将会很大，所以作者在 3x3 卷积之前进行了 1x1 CONV 来压缩通道的个数。因此 H_l = BN + ReLU + 1x1 CONV + BN +
ReLU + 3x3 CONV .称为 Bottleneck layers</p><p>Pooling layers : BN + 1x1 CONV + 2x2 average pooling 。作者称 dense block 中间的连接为 transition layer。为了进一步压缩
模型，这里的 1x1 卷积将用于减少 channel 的个数，将 channel 的个数由 m 减少到 \(\theta m, \ \theta &lt; 1\) ，作者采用了
\(\theta = 0.5\) 。同时采用 Bottleneck 和 Compression 的网络架构称为 DenseNet-BC.</p><p>文中使用了 4 个 dense block ，前面两个 dense block 使用了相同的 L ，后面两个 dense block 的个数不同而形成了不同层数的网
络。</p><p>DenseNet 有更少的参数，更少的运算时间，却可以达到更好的效果。</p><p><strong>猜想</strong> ： 假如把 dense block 当做一种新形式的卷积层，然后按照相似的形式对多个 dense block 进行密集连接，组成更大形式的网
络会怎样？</p></div></div><div id=outline-container-headline-5 class=outline-3><h3 id=headline-5>NIN</h3><div id=outline-text-headline-5 class=outline-text-3><div id=outline-container-headline-6 class=outline-4><h4 id=headline-6>1x1 CONV</h4><div id=outline-text-headline-6 class=outline-text-4><p>对不同的 channel 相同位置的节点进行卷积，来减少 channel 的个数。不仅可以融合不同 channel 的特征，也可以有效减少参数。</p></div></div><div id=outline-container-headline-7 class=outline-4><h4 id=headline-7>Global Average Pooling</h4><div id=outline-text-headline-7 class=outline-text-4><p>全连接层参数过多，容易过拟合，需要 Dropout 等方法来预防。而且这种将前面提取到的特征直接堆叠起来的方法有点不自然。所有作
者提出让每一个 feature map 的全局平均值作为一个节点，有多少个类别就生成多少个 feature map ，然后将所有 feature map 的平
均值输入到 Softmax 进行分类，这样每一个 feature map 代表一类，相比于全连接层，其意义更加明确。而且无需额外的参数，同时可
以融合空间信息。</p><p>Take the average of each feature map, and the resulting map is fed directly into the softmax layer.
Generate one feature map for each corresponding category of the classification task.
Feature map can be easily interpreted as categories confidence map.</p></div></div></div></div><div id=outline-container-headline-8 class=outline-3><h3 id=headline-8>FCN</h3><div id=outline-text-headline-8 class=outline-text-3><p>Fully Convolutional Networks for Semantic Segmentation</p><p>将卷积神经网络中的全连接层变成卷积层，让整个网络全部由卷积操作组成，故称为全卷积网络。</p></div></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://kylestones.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/>深度学习</a></li></ul><nav class=paginav><a class=prev href=https://kylestones.github.io/blog/machinelearning/seethemove/><span class=title>« Prev</span><br><span>见招拆招</span></a>
<a class=next href=https://kylestones.github.io/blog/machinelearning/revolution/><span class=title>Next »</span><br><span>卷积神经网络进化</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share VGG GoogLeNet ResNet on twitter" href="https://twitter.com/intent/tweet/?text=VGG%20GoogLeNet%20ResNet&url=https%3a%2f%2fkylestones.github.io%2fblog%2fmachinelearning%2fvgg-googlenet-resnet%2f&hashtags=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share VGG GoogLeNet ResNet on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fkylestones.github.io%2fblog%2fmachinelearning%2fvgg-googlenet-resnet%2f&title=VGG%20GoogLeNet%20ResNet&summary=VGG%20GoogLeNet%20ResNet&source=https%3a%2f%2fkylestones.github.io%2fblog%2fmachinelearning%2fvgg-googlenet-resnet%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share VGG GoogLeNet ResNet on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fkylestones.github.io%2fblog%2fmachinelearning%2fvgg-googlenet-resnet%2f&title=VGG%20GoogLeNet%20ResNet"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share VGG GoogLeNet ResNet on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fkylestones.github.io%2fblog%2fmachinelearning%2fvgg-googlenet-resnet%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share VGG GoogLeNet ResNet on whatsapp" href="https://api.whatsapp.com/send?text=VGG%20GoogLeNet%20ResNet%20-%20https%3a%2f%2fkylestones.github.io%2fblog%2fmachinelearning%2fvgg-googlenet-resnet%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share VGG GoogLeNet ResNet on telegram" href="https://telegram.me/share/url?text=VGG%20GoogLeNet%20ResNet&url=https%3a%2f%2fkylestones.github.io%2fblog%2fmachinelearning%2fvgg-googlenet-resnet%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://kylestones.github.io>Org Mode</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>