<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>卷积, on Org Mode</title>
    <link>https://kylestones.github.io/hugo-blog/tags/%E5%8D%B7%E7%A7%AF/</link>
    <description>Recent content in 卷积, on Org Mode</description>
    <image>
      <url>https://kylestones.github.io/hugo-blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://kylestones.github.io/hugo-blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://kylestones.github.io/hugo-blog/tags/%E5%8D%B7%E7%A7%AF/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>convolution</title>
      <link>https://kylestones.github.io/hugo-blog/blog/machinelearning/convolution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kylestones.github.io/hugo-blog/blog/machinelearning/convolution/</guid>
      <description>cs231n   斯坦福大学的课程 CS231n: Convolutional Neural Networks for Visual Recognition 。发现写的很好，后悔没有早点看。可惜只看了 卷积这一部分。有中文翻译的部分可以只看中文总结，后面的英文原文更方便理解。 卷积   卷积神经网络明确假设输入是 images ，根据这个假设可以大量的减少参数的个数。同时有利于更 efficient 的实现。普通的神经网 络采用全连接，用于图像中会产生太多的参数，导致 overfitting 。卷积神经网络的 layers 拥有神经元的维数为 (width,height,channels) 。  A ConvNet is made up of Layers. Every Layer has a simple API: It transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters.  卷积操作的本质就是滤波器和输入的部分区域做点积。卷积的反向传播也是卷积，只是做了转置。Note that the convolution operation essentially performs dot products between the filters and local regions of the input.</description>
    </item>
    
  </channel>
</rss>
